{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c340ec-8b30-4804-988c-c15261501c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col,when\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spotify Regression\") \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aac7752-2490-4efc-a61b-803bb47852ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spotify_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- daily_rank: float (nullable = true)\n",
      " |-- daily_movement: float (nullable = true)\n",
      " |-- weekly_movement: float (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- snapshot_date: string (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      " |-- is_explicit: string (nullable = true)\n",
      " |-- duration_ms: float (nullable = true)\n",
      " |-- album_name: string (nullable = true)\n",
      " |-- album_release_date: string (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      " |-- valence: float (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      " |-- time_signature: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"data/df_clean_parquet\")\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d96d2b-cb37-4693-b9f9-9a23fe34017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"daily_rank\", \"energy\", \"loudness\", \"speechiness\",\n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\",\n",
    "    \"valence\", \"tempo\"\n",
    "]\n",
    "label_col = \"popularity_label\"\n",
    "popularity_threshold = 70\n",
    "\n",
    "df = df.withColumn(\n",
    "    label_col,\n",
    "    F.when(F.col(\"popularity\") >= F.lit(popularity_threshold), F.lit(1)).otherwise(F.lit(0))\n",
    ").withColumn(label_col, F.col(label_col).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edda9434-befa-4929-b063-63a0184e90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in numeric_cols if c != \"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d09717-9aae-4373-bf0b-5ebed3d7e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spotify_gbt_pipeline(\n",
    "    numeric_features: list[str],\n",
    "    label_col: str,\n",
    "    max_iter: int\n",
    ") -> Pipeline:\n",
    "\n",
    "    vector_assembler = VectorAssembler(\n",
    "        inputCols=numeric_features,\n",
    "        outputCol=\"num_features\"\n",
    "    )\n",
    "\n",
    "    scaler = MinMaxScaler(\n",
    "        inputCol=\"num_features\",\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    gbt = GBTClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=label_col,\n",
    "        predictionCol=\"prediction\",\n",
    "        maxIter=max_iter,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[vector_assembler, scaler, gbt])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "pipeline = create_spotify_gbt_pipeline(\n",
    "    numeric_features=feature_cols,\n",
    "    label_col=label_col,\n",
    "    max_iter=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fa9865-8ad0-489a-add0-66f12fdecc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7579cae6-9e64-48a8-9e80-28d1ead5a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 795388\n",
      "Test  dataset size: 198883\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {train_df.count()}\")\n",
    "print(f\"Test  dataset size: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7ddce0-5031-417e-aacb-c66e12db059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(pipeline.getStages()[-1].maxDepth, [3, 5]) \\\n",
    "    .addGrid(pipeline.getStages()[-1].stepSize, [0.05, 0.1]) \\\n",
    "    .addGrid(pipeline.getStages()[-1].maxIter, [30]) \\\n",
    "    .build()\n",
    "\n",
    "cv_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=label_col,\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "cross_validator = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=cv_evaluator,\n",
    "    numFolds=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e34117-308e-4bdb-9787-7be36b7c4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cross_validator.fit(train_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099732ff-df84-494a-95fa-1fa0923e30f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели:\n",
      "maxDepth: 5\n",
      "stepSize: 0.1\n",
      "maxIter: 30\n"
     ]
    }
   ],
   "source": [
    "def get_best_model_params(cv_model: CrossValidatorModel) -> dict[str, float]:\n",
    "    best_model = cv_model.bestModel\n",
    "    best_stage = best_model.stages[-1]  # GBTClassifierModel\n",
    "    return {\n",
    "        \"maxDepth\": best_stage.getMaxDepth(),\n",
    "        \"stepSize\": best_stage.getStepSize(),\n",
    "        \"maxIter\": best_stage.getMaxIter()\n",
    "    }\n",
    "\n",
    "print(\"Лучшие параметры модели:\")\n",
    "for k, v in get_best_model_params(cv_model).items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a982b5-b32d-4ea2-bb77-2ecd03e17584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    popularity_label  prediction                                rawPrediction\n",
      "0                  1         1.0    [-1.0965660276393883, 1.0965660276393883]\n",
      "1                  1         1.0    [-1.0965660276393883, 1.0965660276393883]\n",
      "2                  1         1.0    [-1.0965660276393883, 1.0965660276393883]\n",
      "3                  1         1.0    [-1.0965660276393883, 1.0965660276393883]\n",
      "4                  1         1.0    [-1.0965660276393883, 1.0965660276393883]\n",
      "..               ...         ...                                          ...\n",
      "95                 0         0.0      [0.710418835646897, -0.710418835646897]\n",
      "96                 0         0.0    [0.6102443757214819, -0.6102443757214819]\n",
      "97                 0         1.0  [-0.34375779585723115, 0.34375779585723115]\n",
      "98                 1         1.0    [-0.6598621365216315, 0.6598621365216315]\n",
      "99                 1         1.0    [-0.6598621365216315, 0.6598621365216315]\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df_predictions = cv_model.transform(test_df)\n",
    "\n",
    "pred_pd = (\n",
    "    test_df_predictions\n",
    "    .select(label_col, \"prediction\", \"rawPrediction\")\n",
    "    .limit(100)\n",
    "    .toPandas()\n",
    ")\n",
    "print(pred_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe459ebf-2b88-4e66-8d7c-a52a8d225e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (areaUnderROC): 0.8631\n",
      "Metrics: {'precision': 0.8178026832076314, 'recall': 0.9545900211862954, 'f1': 0.8809179576896674}\n"
     ]
    }
   ],
   "source": [
    "auc = cv_evaluator.evaluate(test_df_predictions)\n",
    "print(f\"AUC (areaUnderROC): {auc:.4f}\")\n",
    "\n",
    "def evaluate_model_binary(data, label_col: str) -> dict[str, float]:\n",
    "    tp = data.filter((F.col(label_col) == 1) & (F.col(\"prediction\") == 1)).count()\n",
    "    fp = data.filter((F.col(label_col) == 0) & (F.col(\"prediction\") == 1)).count()\n",
    "    fn = data.filter((F.col(label_col) == 1) & (F.col(\"prediction\") == 0)).count()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "metrics = evaluate_model_binary(test_df_predictions, label_col)\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe375285-3be4-4e96-b796-3ab1a88c4a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
